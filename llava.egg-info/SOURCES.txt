LICENSE
README.md
pyproject.toml
setup.py
bitnet_b1_58_3B/configuration_bitnet.py
bitnet_b1_58_3B/eval_ppl.py
bitnet_b1_58_3B/eval_task.py
bitnet_b1_58_3B/eval_utils.py
bitnet_b1_58_3B/modeling_bitnet.py
bitnet_b1_58_3B/tokenization_bitnet.py
bitnet_b1_58_3B/utils_quant.py
flash-attention/setup.py
flash-attention/benchmarks/benchmark_causal.py
flash-attention/benchmarks/benchmark_flash_attention.py
flash-attention/csrc/cutlass/examples/40_cutlass_py/conv2d.py
flash-attention/csrc/cutlass/examples/40_cutlass_py/gemm.py
flash-attention/csrc/cutlass/examples/40_cutlass_py/gemm_grouped.py
flash-attention/csrc/cutlass/examples/40_cutlass_py/customizable/conv2d.py
flash-attention/csrc/cutlass/examples/40_cutlass_py/customizable/gemm.py
flash-attention/csrc/cutlass/examples/40_cutlass_py/customizable/gemm_grouped.py
flash-attention/csrc/cutlass/examples/41_fused_multi_head_attention/fmha_backward_test.py
flash-attention/csrc/cutlass/examples/41_fused_multi_head_attention/piped_subprocess.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/gen_all_code.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/gen_cmake.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/gen_customized_epilogue.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/gen_device.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/gen_ir.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/gen_kernel.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/gen_sample.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/gen_threadblock.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/gen_turing_and_volta.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/gen_verify.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/helper.py
flash-attention/csrc/cutlass/examples/44_multi_gemm_ir_and_codegen/ir_gen/replace_fix_impl_header.py
flash-attention/csrc/cutlass/python/setup.py
flash-attention/csrc/cutlass/python/cutlass/__init__.py
flash-attention/csrc/cutlass/python/cutlass/epilogue.py
flash-attention/csrc/cutlass/python/cutlass/library_defaults.py
flash-attention/csrc/cutlass/python/cutlass/swizzle.py
flash-attention/csrc/cutlass/python/cutlass/backend/__init__.py
flash-attention/csrc/cutlass/python/cutlass/backend/arguments.py
flash-attention/csrc/cutlass/python/cutlass/backend/c_types.py
flash-attention/csrc/cutlass/python/cutlass/backend/compiler.py
flash-attention/csrc/cutlass/python/cutlass/backend/conv2d_operation.py
flash-attention/csrc/cutlass/python/cutlass/backend/epilogue.py
flash-attention/csrc/cutlass/python/cutlass/backend/frontend.py
flash-attention/csrc/cutlass/python/cutlass/backend/gemm_operation.py
flash-attention/csrc/cutlass/python/cutlass/backend/library.py
flash-attention/csrc/cutlass/python/cutlass/backend/memory_manager.py
flash-attention/csrc/cutlass/python/cutlass/backend/operation.py
flash-attention/csrc/cutlass/python/cutlass/backend/parser.py
flash-attention/csrc/cutlass/python/cutlass/backend/reduction_operation.py
flash-attention/csrc/cutlass/python/cutlass/backend/tensor_ref.py
flash-attention/csrc/cutlass/python/cutlass/backend/type_hint.py
flash-attention/csrc/cutlass/python/cutlass/backend/test/__init__.py
flash-attention/csrc/cutlass/python/cutlass/backend/test/conv2d_testbed.py
flash-attention/csrc/cutlass/python/cutlass/backend/test/gemm_grouped_testbed.py
flash-attention/csrc/cutlass/python/cutlass/backend/test/gemm_testbed.py
flash-attention/csrc/cutlass/python/cutlass/backend/test/profiler.py
flash-attention/csrc/cutlass/python/cutlass/backend/test/utils.py
flash-attention/csrc/cutlass/python/cutlass/backend/utils/__init__.py
flash-attention/csrc/cutlass/python/cutlass/backend/utils/datatypes.py
flash-attention/csrc/cutlass/python/cutlass/backend/utils/device.py
flash-attention/csrc/cutlass/python/cutlass/backend/utils/reference_model.py
flash-attention/csrc/cutlass/python/cutlass/backend/utils/software.py
flash-attention/csrc/cutlass/python/cutlass/emit/__init__.py
flash-attention/csrc/cutlass/python/cutlass/emit/common.py
flash-attention/csrc/cutlass/python/cutlass/emit/pytorch.py
flash-attention/csrc/cutlass/python/cutlass/op/__init__.py
flash-attention/csrc/cutlass/python/cutlass/op/conv.py
flash-attention/csrc/cutlass/python/cutlass/op/gemm.py
flash-attention/csrc/cutlass/python/cutlass/op/gemm_grouped.py
flash-attention/csrc/cutlass/python/cutlass/op/op.py
flash-attention/csrc/cutlass/python/cutlass/utils/__init__.py
flash-attention/csrc/cutlass/python/cutlass/utils/check.py
flash-attention/csrc/cutlass/python/cutlass/utils/datatypes.py
flash-attention/csrc/cutlass/python/docs_src/source/conf.py
flash-attention/csrc/cutlass/test/python/backend/conv/__init__.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/conv/run_all_tests.py
flash-attention/csrc/cutlass/test/python/backend/gemm/__init__.py
flash-attention/csrc/cutlass/test/python/backend/gemm/gemm_bf16_sm80.py
flash-attention/csrc/cutlass/test/python/backend/gemm/gemm_bf16_sm90.py
flash-attention/csrc/cutlass/test/python/backend/gemm/gemm_f16_sm80.py
flash-attention/csrc/cutlass/test/python/backend/gemm/gemm_f16_sm90.py
flash-attention/csrc/cutlass/test/python/backend/gemm/gemm_f32_sm80.py
flash-attention/csrc/cutlass/test/python/backend/gemm/gemm_f64_sm80.py
flash-attention/csrc/cutlass/test/python/backend/gemm/gemm_f64_sm90.py
flash-attention/csrc/cutlass/test/python/backend/gemm/gemm_grouped_sm80.py
flash-attention/csrc/cutlass/test/python/backend/gemm/gemm_s8_sm80.py
flash-attention/csrc/cutlass/test/python/backend/gemm/gemm_s8_sm90.py
flash-attention/csrc/cutlass/test/python/backend/gemm/run_all_tests.py
flash-attention/csrc/cutlass/test/python/conv2d/conv2d_sm80.py
flash-attention/csrc/cutlass/test/python/conv2d/conv2d_test_utils.py
flash-attention/csrc/cutlass/test/python/conv2d/run_all_tests.py
flash-attention/csrc/cutlass/test/python/emit/pytorch.py
flash-attention/csrc/cutlass/test/python/gemm/gemm_batched.py
flash-attention/csrc/cutlass/test/python/gemm/gemm_f16_sm80.py
flash-attention/csrc/cutlass/test/python/gemm/gemm_f16_sm90.py
flash-attention/csrc/cutlass/test/python/gemm/gemm_f32_sm80.py
flash-attention/csrc/cutlass/test/python/gemm/gemm_f64_sm80.py
flash-attention/csrc/cutlass/test/python/gemm/gemm_f64_sm90.py
flash-attention/csrc/cutlass/test/python/gemm/gemm_s8_sm80.py
flash-attention/csrc/cutlass/test/python/gemm/gemm_s8_sm90.py
flash-attention/csrc/cutlass/test/python/gemm/run_all_tests.py
flash-attention/csrc/cutlass/test/python/interface/conv2d_interface.py
flash-attention/csrc/cutlass/test/python/interface/gemm_interface.py
flash-attention/csrc/cutlass/test/python/interface/utils.py
flash-attention/csrc/cutlass/test/unit/gemm/device/simt_sm50.py
flash-attention/csrc/cutlass/tools/library/scripts/__init__.py
flash-attention/csrc/cutlass/tools/library/scripts/conv2d_operation.py
flash-attention/csrc/cutlass/tools/library/scripts/conv3d_operation.py
flash-attention/csrc/cutlass/tools/library/scripts/gemm_operation.py
flash-attention/csrc/cutlass/tools/library/scripts/generator.py
flash-attention/csrc/cutlass/tools/library/scripts/library.py
flash-attention/csrc/cutlass/tools/library/scripts/manifest.py
flash-attention/csrc/cutlass/tools/library/scripts/rank_2k_operation.py
flash-attention/csrc/cutlass/tools/library/scripts/rank_k_operation.py
flash-attention/csrc/cutlass/tools/library/scripts/rt.py
flash-attention/csrc/cutlass/tools/library/scripts/symm_operation.py
flash-attention/csrc/cutlass/tools/library/scripts/trmm_operation.py
flash-attention/csrc/flash_attn/src/generate_kernels.py
flash-attention/csrc/ft_attention/setup.py
flash-attention/csrc/fused_dense_lib/setup.py
flash-attention/csrc/fused_softmax/setup.py
flash-attention/csrc/layer_norm/setup.py
flash-attention/csrc/rotary/setup.py
flash-attention/csrc/xentropy/setup.py
flash-attention/flash_attn/__init__.py
flash-attention/flash_attn/bert_padding.py
flash-attention/flash_attn/flash_attn_interface.py
flash-attention/flash_attn/flash_attn_triton.py
flash-attention/flash_attn/flash_attn_triton_og.py
flash-attention/flash_attn/flash_blocksparse_attention.py
flash-attention/flash_attn/flash_blocksparse_attn_interface.py
flash-attention/flash_attn/fused_softmax.py
flash-attention/flash_attn/layers/__init__.py
flash-attention/flash_attn/layers/patch_embed.py
flash-attention/flash_attn/layers/rotary.py
flash-attention/flash_attn/losses/__init__.py
flash-attention/flash_attn/losses/cross_entropy.py
flash-attention/flash_attn/models/__init__.py
flash-attention/flash_attn/models/baichuan.py
flash-attention/flash_attn/models/bert.py
flash-attention/flash_attn/models/bigcode.py
flash-attention/flash_attn/models/falcon.py
flash-attention/flash_attn/models/gpt.py
flash-attention/flash_attn/models/gpt_neox.py
flash-attention/flash_attn/models/gptj.py
flash-attention/flash_attn/models/llama.py
flash-attention/flash_attn/models/opt.py
flash-attention/flash_attn/models/vit.py
flash-attention/flash_attn/modules/__init__.py
flash-attention/flash_attn/modules/block.py
flash-attention/flash_attn/modules/embedding.py
flash-attention/flash_attn/modules/mha.py
flash-attention/flash_attn/modules/mlp.py
flash-attention/flash_attn/ops/__init__.py
flash-attention/flash_attn/ops/activations.py
flash-attention/flash_attn/ops/fused_dense.py
flash-attention/flash_attn/ops/layer_norm.py
flash-attention/flash_attn/ops/rms_norm.py
flash-attention/flash_attn/ops/triton/__init__.py
flash-attention/flash_attn/ops/triton/cross_entropy.py
flash-attention/flash_attn/ops/triton/k_activations.py
flash-attention/flash_attn/ops/triton/linear.py
flash-attention/flash_attn/ops/triton/mlp.py
flash-attention/flash_attn/ops/triton/rotary.py
flash-attention/flash_attn/utils/__init__.py
flash-attention/flash_attn/utils/benchmark.py
flash-attention/flash_attn/utils/distributed.py
flash-attention/flash_attn/utils/generation.py
flash-attention/flash_attn/utils/pretrained.py
flash-attention/tests/test_flash_attn.py
flash-attention/tests/test_rotary.py
flash-attention/tests/layers/test_rotary.py
flash-attention/tests/losses/test_cross_entropy.py
flash-attention/tests/losses/test_cross_entropy_parallel.py
flash-attention/tests/models/test_baichuan.py
flash-attention/tests/models/test_bert.py
flash-attention/tests/models/test_bigcode.py
flash-attention/tests/models/test_falcon.py
flash-attention/tests/models/test_gpt.py
flash-attention/tests/models/test_gpt_generation_parallel.py
flash-attention/tests/models/test_gpt_neox.py
flash-attention/tests/models/test_gpt_parallel.py
flash-attention/tests/models/test_gptj.py
flash-attention/tests/models/test_llama.py
flash-attention/tests/models/test_opt.py
flash-attention/tests/models/test_vit.py
flash-attention/tests/modules/test_block_parallel.py
flash-attention/tests/modules/test_embedding_parallel.py
flash-attention/tests/modules/test_mha_parallel.py
flash-attention/tests/modules/test_mlp_parallel.py
flash-attention/tests/ops/test_dropout_layer_norm.py
flash-attention/tests/ops/test_fused_dense.py
flash-attention/tests/ops/test_fused_dense_parallel.py
flash-attention/training/run.py
flash-attention/training/src/eval.py
flash-attention/training/src/train.py
flash-attention/training/src/callbacks/__init__.py
flash-attention/training/src/callbacks/causality_monitor.py
flash-attention/training/src/callbacks/ema.py
flash-attention/training/src/callbacks/flop_count.py
flash-attention/training/src/callbacks/gpu_affinity.py
flash-attention/training/src/callbacks/loss_scale_monitor.py
flash-attention/training/src/callbacks/model_checkpoint.py
flash-attention/training/src/callbacks/norm_monitor.py
flash-attention/training/src/callbacks/params_log.py
flash-attention/training/src/callbacks/speed_monitor.py
flash-attention/training/src/callbacks/wandb_callbacks.py
flash-attention/training/src/datamodules/fault_tolerant_sampler.py
flash-attention/training/src/datamodules/imagenet.py
flash-attention/training/src/datamodules/language_modeling_hf.py
flash-attention/training/src/datamodules/timm_mixup.py
flash-attention/training/src/datamodules/datasets/detokenizer.py
flash-attention/training/src/datamodules/datasets/lm_dataset.py
flash-attention/training/src/distributed/ddp_comm_hooks.py
flash-attention/training/src/metrics/accuracy.py
flash-attention/training/src/metrics/num_tokens.py
flash-attention/training/src/metrics/perplexity.py
flash-attention/training/src/models/modules/seq_common.py
flash-attention/training/src/optim/param_grouping.py
flash-attention/training/src/optim/timm_lr_scheduler.py
flash-attention/training/src/tasks/seq.py
flash-attention/training/src/utils/checkpoint.py
flash-attention/training/src/utils/ddp_zero1.py
flash-attention/training/src/utils/ddp_zero2.py
flash-attention/training/src/utils/distributed.py
flash-attention/training/src/utils/ema.py
flash-attention/training/src/utils/flops.py
flash-attention/training/src/utils/gpu_affinity.py
flash-attention/training/src/utils/utils.py
flash-attention/training/tests/datamodules/test_language_modeling_hf.py
llava/__init__.py
llava/constants.py
llava/conversation.py
llava/llava_bitnet_b1_58_3B_explore.py
llava/mm_utils.py
llava/utils.py
llava.egg-info/PKG-INFO
llava.egg-info/SOURCES.txt
llava.egg-info/dependency_links.txt
llava.egg-info/requires.txt
llava.egg-info/top_level.txt
llava/eval/eval_gpt_review.py
llava/eval/eval_gpt_review_bench.py
llava/eval/eval_gpt_review_visual.py
llava/eval/eval_pope.py
llava/eval/eval_science_qa.py
llava/eval/eval_science_qa_gpt4.py
llava/eval/eval_textvqa.py
llava/eval/generate_webpage_data_from_table.py
llava/eval/m4c_evaluator.py
llava/eval/model_qa.py
llava/eval/model_vqa.py
llava/eval/model_vqa_loader.py
llava/eval/model_vqa_mmbench.py
llava/eval/model_vqa_qbench.py
llava/eval/model_vqa_science.py
llava/eval/model_vqa_science_efficient.py
llava/eval/qa_baseline_gpt35.py
llava/eval/run_llava.py
llava/eval/summarize_gpt_review.py
llava/model/__init__.py
llava/model/apply_delta.py
llava/model/builder.py
llava/model/config.py
llava/model/consolidate.py
llava/model/llava_arch.py
llava/model/make_delta.py
llava/model/utils.py
llava/model/language_model/llava_bitnet_b1_58_3B.py
llava/model/language_model/llava_llama.py
llava/model/language_model/llava_mpt.py
llava/model/language_model/mpt/adapt_tokenizer.py
llava/model/language_model/mpt/attention.py
llava/model/language_model/mpt/blocks.py
llava/model/language_model/mpt/configuration_mpt.py
llava/model/language_model/mpt/custom_embedding.py
llava/model/language_model/mpt/flash_attn_triton.py
llava/model/language_model/mpt/hf_prefixlm_converter.py
llava/model/language_model/mpt/meta_init_context.py
llava/model/language_model/mpt/modeling_mpt.py
llava/model/language_model/mpt/norm.py
llava/model/language_model/mpt/param_init_fns.py
llava/model/multimodal_encoder/builder.py
llava/model/multimodal_encoder/clip_encoder.py
llava/model/multimodal_projector/builder.py
llava/serve/__init__.py
llava/serve/cli.py
llava/serve/controller.py
llava/serve/gradio_web_server.py
llava/serve/model_worker.py
llava/serve/register_worker.py
llava/serve/test_message.py
llava/train/llama_flash_attn_monkey_patch.py
llava/train/llama_xformers_attn_monkey_patch.py
llava/train/llava_trainer.py
llava/train/train.py
llava/train/train_mem.py
llava/train/train_xformers.py